{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc28798-22d3-41fb-9bd2-826bd266bdf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hands-On Assignment 2\n",
    "\n",
    "As we saw in Module 2, machine learning is about optimizing over a loss.\n",
    "How well a machine learning model performs depends on both the hypothesis and loss function that we choose to use.\n",
    "This general framework of goes under the name of *[empirical risk minimization](https://en.wikipedia.org/wiki/Empirical_risk_minimization)*.\n",
    "\n",
    "In this assignment, we will walk you through the basic steps of empirical risk minimization: the optimization problem at the heart of most modern-day machine learning systems.\n",
    "We will use a simple motivating example for an end-to-end demonstration: predicting whether a patient with a given antigen test value is infected with Covid-19.\n",
    "Using the same synthetic Covid-19 dataset you worked with in [Hands-On Assignment 1](https://github.com/ucsc-cse-40/HO1),\n",
    "we will train a simple [classifier](https://en.wikipedia.org/wiki/Statistical_classification) that predicts that an individual is infected with Covid-19 if and only if their test value is above a certain threshold.\n",
    "\n",
    "This assignment is divided into three parts:\n",
    "1. We will first set up a basic empirical risk minimization problem.\n",
    "2. Next, we will find a hypothesis that results in a small loss.\n",
    "3. Finally, we will evaluate our solution and the associated risks of deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b418121-5107-4fde-aead-ae752f9bd1c9",
   "metadata": {},
   "source": [
    "## Part 1: Setting up the Problem\n",
    "\n",
    "In this part we will setup the empirical risk minimization problem we wish to solve, by:\n",
    " - Defining our variables of interest.\n",
    " - Choosing a \"hypothesis class\" $ \\mathcal{H} $, or space of possible solutions, that we will search.\n",
    " - Selecting a \"loss function\" $ L $ that will be minimized by our learned solution, thus encoding our objective.\n",
    "\n",
    "### Empirical Risk Minimization - The Big Picture\n",
    "\n",
    "Empirical risk minimization is about trying to come up with a function (usually called a *hypothesis*) that can make correct predictions as often as possible.\n",
    "The more our hypothesis is correct, the lower the *risk* of that hypothesis.\n",
    "A hypothesis that is always correct has zero risk.\n",
    "\n",
    "But in real life, it's almost always impossible to make something that is always correct.\n",
    "(If we could, there would be no point in machine learning.)\n",
    "It's also impossible for us to always know when our hypothesis is right or wrong (imagine trying to predict something for every person in the world (past, present, and future)).\n",
    "\n",
    "So since we can't compute the true risk of a hypothesis, we instead approximate it by computing an *empirical risk*.\n",
    "To do this, we narrow down our set of data points from every possible data point to a known set of training data.\n",
    "We can then compute our average loss over our known data to compute our empirical risk.\n",
    "\n",
    "### Empirical Risk Minimization - Mathematical Formalism\n",
    "\n",
    "Now, let's put our intuition from the previous section into math.\n",
    "\n",
    "Empirical risk minimization is the **minimization** (over several possible hypotheses $\\mathcal{H}$) of the expected loss (i.e. *risk*) of a hypothesis $ h $ with the data $ Z $:\n",
    "$$\n",
    "\\min_{h \\in \\mathcal{H}} \\mathbb{E}_Z \\Big[ L(Z, h) \\Big]\n",
    "$$\n",
    "\n",
    "Here we are taking the [expectation](https://en.wikipedia.org/wiki/Expected_value) ($ \\mathbb{E} $) over all possible values of the data.\n",
    "If you haven’t seen expectation before, we will discuss it in detail in a future module.\n",
    "But for now, you can think of expectation as the average value we would get if we randomly sampled infinite data points.\n",
    "For example, if we fairly picked random numbers between 1 and 99 (inclusive),\n",
    "then the expected value (expectation) would be 50.\n",
    "You can make a small Python program to try it out yourself.\n",
    "\n",
    "Using a finite set of empirical data $ Z = \\{z_1, z_2, z_3, ..., z_N \\} $, we can say that:\n",
    "$$\n",
    "\\mathbb{E}_{Z} \\Big[ L(Z, h) \\Big] \\approx \\frac{1}{N} \\sum_{i=1}^N L(z_i, h)\n",
    "$$\n",
    "\n",
    "Note that in our equation, we are dividing the loss by the number of data points, $ N $.\n",
    "This allows us to compute the *expected loss*,\n",
    "which is the amount that we expect each prediction to be off by.\n",
    "Another common way of using loss, that you may have seen in class,\n",
    "is using the *total loss*.\n",
    "The total loss is computed the same as the expected loss, but does not average over all data points (doesn't divide by $ N $).\n",
    "Using either the expected or total loss leads to the same answer for this problem.\n",
    "In the future, we will discuss when using one would be more appropriate than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896430e-0a5d-471c-9c1f-f03a345e8951",
   "metadata": {
    "tags": []
   },
   "source": [
    "### A Motivating Example using Synthetic Covid-19 Data\n",
    "\n",
    "As a motivating example, let's try to use the synthetic Covid-19 data used in HO1 to predict whether a patient has Covid-19.\n",
    "For this task, we are given previous examples of asymptomatic patients (and their Covid-19 infection status),\n",
    "and we are going to assume that these examples accurately represent patients that we may see in the future.\n",
    "This assumption we are making is called the [i.i.d. assumption](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables),\n",
    "and it is one of the cornerstones of many machine learning algorithms.\n",
    "The independent and identically distributed (i.i.d.) assumption assumes that all random variables (each patient in this example),\n",
    "are *independent* (one patient being infected does not affect whether another patient is infected),\n",
    "and *identically distributed* (future patients will have similar features to the patients we have already seen)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d931a-312b-4d5e-bd71-0a17018780c9",
   "metadata": {},
   "source": [
    "Let's load this set of previous examples, included in this repository as `synthetic_covid_data.csv`, using Python and briefly consider its content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2e629c-407a-41ca-a7d0-45557c91238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Read data from the given csv file to a Pandas dataframe\n",
    "covid_data = pandas.read_csv('synthetic_covid_data.csv', index_col = 0)\n",
    "\n",
    "# Column and type information\n",
    "covid_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399ca700-1100-4804-a0ff-8c563af61d91",
   "metadata": {},
   "source": [
    "Inspecting the dataframe information, we see that this dataset contains the following columns:\n",
    " - `infected` (as a boolean) - whether a patient had Covid-19.\n",
    " - `symptomatic` (as a boolean) - whether a patient developed symptoms.\n",
    " - `days_before_symptoms` (as a float) - how many days after testing the patient developed symptoms, if they did.\n",
    " - `titer` (as an integer) - how many times bodily fluids could be diluted before antigen was no longer detectable.\n",
    "\n",
    "We also note that Pandas tells us that `days_before_symptoms` contains mostly null/undefined content (only 138 non-null values).\n",
    "\n",
    "We can get an impression of the ranges and statistics of numerical columns by calling `covid_data.describe()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b8d5f-cfed-421d-a2f2-46b51105c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe numerical column statistics.\n",
    "covid_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d14598-3db5-4744-9569-0cb40f97faf2",
   "metadata": {},
   "source": [
    "### Defining Variables of Interest: Features and Labels\n",
    "\n",
    "The first step in empirical risk minimization is to define our features ($ X $) and labels ($ Y $).\n",
    "\n",
    "The features (as discussed in HO1) are the meaningful numbers that we associate with a data point.\n",
    "In our Covid-19 data, we have three columns that can be used as features: `symptomatic`, `days_before_symptoms`, and `titer`.\n",
    "To keep things simple, we will only use one feature in this assignment: the `titer` column.\n",
    "Although we will only use one feature column in this assignment, most machine learning models use tens, hundreds, thousands, or even more feature columns.\n",
    "\n",
    "For our label, we will use the `infected` column.\n",
    "The label assigns each data point to a specific class (in this case, *infected* or *not infected*).\n",
    "Labels can take a wide range of values, for example if you are trying to classify the contents of an image there can be many possible labels: dog, cat, person, etc.\n",
    "In this assignment we are focusing on [binary classification](https://en.wikipedia.org/wiki/Binary_classification),\n",
    "where the label can only be True (1) of False (0).\n",
    "\n",
    "Together, the features ($ X $) and labels ($ Y $) define our dataset $ Z $:\n",
    "$$\n",
    "Z = (X, Y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d817adb-c944-4fc6-a41e-9315d48c5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels from the dataframe.\n",
    "Y_values = covid_data['infected']\n",
    "X_values = covid_data['titer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5dfd3c-52f6-4cac-8107-f48956d98b60",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Briefly Interpreting the Data\n",
    "\n",
    "In this dataset, a \"titer\" value roughly measures the concentration of a specific antigen produced by a Covid-19 infection.\n",
    "Having run `covid_data.describe()`, we see that titer values in this dataset are integers ranging from `0` to `45`,\n",
    "with at least 75% of examples having titer values of `1` or less.\n",
    "We can visualize the relationship between titer and Covid-19 infections in our data by plotting the sampled frequency of Covid-19 infection vs titer values\n",
    "(i.e., for each titer value, plot the percent of patients that have that titer value and are infected):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0493335-155a-4208-8228-b5c5a5c36620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_infection_probability_vs_titer(df):\n",
    "    \"\"\"\n",
    "    Plot the infected rate of Covid-19 vs titer value.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get all the possible titer values in a list.\n",
    "    titer_values = list(range(df['titer'].min(), df['titer'].max() + 1))\n",
    "    infected_rate = []\n",
    "\n",
    "    for titer_value in titer_values:\n",
    "        infected_count = len(df[(df['titer'] == titer_value) & df['infected']])\n",
    "        count = len(df[(df['titer'] == titer_value)])\n",
    "\n",
    "        if (count == 0):\n",
    "            # Matplotlib will ignore None/NaN values.\n",
    "            infected_rate.append(None)\n",
    "        else:\n",
    "            infected_rate.append(infected_count / count)\n",
    "\n",
    "    pyplot.plot(infected_rate)\n",
    "    pyplot.title('Sample Frequency of Covid-19 Infection vs Titer Value')\n",
    "    pyplot.xlabel('Titer')\n",
    "    pyplot.ylabel('Precentage Infected')\n",
    "\n",
    "plot_infection_probability_vs_titer(covid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518940cb-a784-4ce6-8731-d8f8dbc2a9d0",
   "metadata": {},
   "source": [
    "In the above graph we can see, perhaps surprisingly,\n",
    "that many patients with low (but not zero) titer values are actually infected.\n",
    "The graph shows that at a titer value of 0, we don't see any infected individuals;\n",
    "at a titer value of 10, about 100% if patients are infected;\n",
    "at a titer value of 20, the infection rate drops to around 20%;\n",
    "and finally at a titer value of 40, the infection rate climbs back up to around 80%.\n",
    "Unfortunately, biology is rarely very simple.\n",
    "\n",
    "To make more sense of our data, we can separate out the data into infected and uninfected individuals.\n",
    "Specifically, we can see what percentage of each population (infected/uninfected) exist at each titer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76497a0a-3dc5-4453-aec3-58cdac8e8705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conditional_probability_density_functions(df):\n",
    "    \"\"\"\n",
    "    Plot probability density of titer value conditioned on Covid-19 infection.\n",
    "    \"\"\"\n",
    "\n",
    "    titer_values = list(range(df['titer'].min(), df['titer'].max() + 1))\n",
    "    infected = df[df['infected']]['titer']\n",
    "    uninfected = df[~df['infected']]['titer']\n",
    "\n",
    "    pyplot.title('Probability Density of Titer Concentration')\n",
    "    pyplot.xlabel('Titer')\n",
    "    infected.plot(kind = 'density', label = 'Infected', ind = titer_values)\n",
    "    uninfected.plot(kind = 'density', label = 'Uninfected', ind = titer_values)\n",
    "    pyplot.legend()\n",
    "\n",
    "plot_conditional_probability_density_functions(covid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c14905-01b9-44a0-a9b1-b6b9953e2593",
   "metadata": {},
   "source": [
    "Looking at this graph, we can discover some important details about our data.\n",
    "While most uninfected individuals have very low titer values (under 5),\n",
    "some small percentage of (isoantigenic) uninfected individuals have reasonable high titer values (widely distributed around 25).\n",
    "Meanwhile, infected individuals appear to belong to two groups:\n",
    "one with relatively small titer values (less than 10) and one with much higher titer values (centered around 30)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e1926-be12-443a-a692-d4cb14064dfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Choosing a Hypothesis Class to Search\n",
    "\n",
    "Now that we have explored our data, it is time to try and make predictions.\n",
    "\n",
    "Recall that we wish to predict a patients' labels $ Y = \\{ y_1, y_2, ..., y_N \\} $ from patients' features $ X = \\{ x_1, x_2, ..., x_N \\} $.\n",
    "That is, our task is to predict each $ y_i $ from $ x_i $, approximating the true mapping $ f $ such that\n",
    "$$\n",
    "\\forall i, \\quad f(x_i) \\mapsto y_i\n",
    "$$\n",
    "\n",
    "Since we can never expect to find $ f $ in real problem (since it is a theoretically perfect predictor),\n",
    "we will use different hypotheses to approximate it.\n",
    "A hypothesis is just a function that maps features to a label.\n",
    "We will denote a general hypothesis with the variable $ h $.\n",
    "Since we cannot guarantee our hypothesis, $ h $, is always correct,\n",
    "we denote its output with $ \\hat{Y} $ (pronounced \"Y-hat\").\n",
    "We say that $ Y $ is the \"true label\" and $ \\hat{Y} $ is the \"predicted label\".\n",
    "$$\n",
    "\\forall i, \\quad h(x_i) \\mapsto \\hat{y}_i\n",
    "$$\n",
    "\n",
    "Note that we will often relax our notation so that the input to a hypothesis function can either be a single data point ($ h(x_i) \\mapsto \\hat{y}_i $) or many data points ($ h(X) \\mapsto \\hat{Y} $)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2a109-311f-4419-8007-9633e8e3210b",
   "metadata": {},
   "source": [
    "#### An Example Hypothesis\n",
    "\n",
    "As a simple example of a hypothesis $ h $,\n",
    "we might predict $ \\hat{y}_i = 1 $ if and only if $ x_i $ is odd.\n",
    "It turns out that this hypothesis is correct more often than random guessing (which would yield 50% accuracy) ... but this doesn't seem like a principled hypothesis for the task at hand\n",
    "(we just got lucky)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1887792-d9d7-4169-bdde-f2d03004ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_odd(feature_value):\n",
    "    \"\"\"\n",
    "    An example hypothesis that guesses True (1) if the input is odd.\n",
    "    \"\"\"\n",
    "\n",
    "    return feature_value % 2\n",
    "\n",
    "# Note that Pandas understands how to do \"% 2\" on an entire series,\n",
    "# so our hypothesis function works for single values and Pandas series.\n",
    "Y_predicted = is_odd(X_values)\n",
    "\n",
    "accuracy = sum(Y_values == Y_predicted) / len(covid_data)\n",
    "print(f\"The accuracy of predicting Ŷ = 1 iff X is odd is {accuracy * 100}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf6aa23-ca69-4745-82dd-9f58471b58b0",
   "metadata": {},
   "source": [
    "#### An Example Hypothesis Class\n",
    "\n",
    "Having only a single possible hypothesis is not very interesting or useful.\n",
    "Instead, we want to try out and evaluate multiple different hypotheses.\n",
    "When we group together multiple hypotheses, we call this a *hypothesis class*, denoted by $ \\mathcal{H} $.\n",
    "\n",
    "Let's consider a class of two competing hypotheses:\n",
    "$ h_0 $ that predicts $ \\hat{Y} = 0 $ for all examples,\n",
    "and $ h_1 $ that always predicts $ \\hat{Y} = 1 $.\n",
    "$$\n",
    "\\mathcal{H} = \\Big\\{ h_0, h_1 \\Big\\}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\forall X, \\quad h_0(X) = 0 \\quad h_1(X) = 1\n",
    "$$\n",
    "Note that both of these hypotheses are independent of $ X $ ($ X $ does not affect what value the hypotheses predict).\n",
    "\n",
    "Now that we have two possible hypotheses,\n",
    "we can conduct experiments to compare them on our data and select the hypothesis that performs the best.\n",
    "Since only $ \\approx $ 5% of individuals in our dataset are Covid-19 positive,\n",
    "$ h_0 $ will match the true mapping $ f $ on 95% of examples (while $ h_1 $ is only correct 5% of the time).\n",
    "If we decide the best hypothesis using maximum accuracy,\n",
    "then $ h_0 $ will look like the best hypothesis and we will always predict that patients are not infected with Covid-19.\n",
    "\n",
    "Obviously, this class of hypotheses is too naïve and we need a richer hypothesis space to search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e0a9b-7415-4ffa-b076-f993a09db80a",
   "metadata": {},
   "source": [
    "#### A Parametric Hypothesis Class\n",
    "\n",
    "If we look back to our naïve hypothesis class $ \\mathcal{H} = \\{h_0, h_1\\} $,\n",
    "we can generalize these hypotheses a bit if recognize that both $ h_0 $ and $ h_1 $ are *threshold* classifiers.\n",
    "That is, the value of each function can be expressed in terms of a comparison of $ X $ to some *threshold* value:\n",
    "\\begin{align*}\n",
    "    h_0(X) &= \\begin{cases} 1 & X > \\infty \\\\\n",
    "                            0 & X \\leq \\infty \\end{cases} \\\\\n",
    "    h_1(X) &= \\begin{cases} 1 & X > -\\infty \\\\\n",
    "                            0 & X \\leq -\\infty \\end{cases}\n",
    "\\end{align*}\n",
    "In this case, our threshold values were the extreme ends of the spectrum: $ \\infty $ and $ -\\infty $.\n",
    "\n",
    "Now what if, instead of these extreme threshold values, we choose a more meaningful value like `20`?\n",
    "\\begin{align*}\n",
    "    h(X) &= \\begin{cases} 1 & X > 20 \\\\\n",
    "                          0 & X \\leq 20 \\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "Now, we can also abstract out the specific threshold value for a variable, $ \\theta $:\n",
    "\\begin{align*}\n",
    "    h(X, \\theta) &= \\begin{cases} 1 & X > \\theta \\\\\n",
    "                                  0 & X \\leq \\theta \\end{cases}\n",
    "\\end{align*}\n",
    "We can recover all of our previous hypothesis using this more general form:\n",
    "\\begin{align*}\n",
    "    h(X, \\infty) \\\\\n",
    "    h(X, -\\infty) \\\\\n",
    "    h(X, 20)\n",
    "\\end{align*}\n",
    "\n",
    "We can even apply our new general hypothesis to our Covid-19 data.\n",
    "Let $h(X, \\theta)$ predict that a patient is infected with Covid-19 ($ \\hat{Y} = 1 $) if and only if `titer` $ X $ is above the threshold value $ \\theta $:\n",
    "$$\n",
    "    h(X, \\theta) = \\begin{cases}\n",
    "    1 & X > \\theta  \\\\\n",
    "    0 & X \\leq \\theta\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "Since we now have a general and parameterized hypothesis function,\n",
    "we can use it to define *all possible hypotheses* our function can represent.\n",
    "This set of all possible hypotheses is called a \"hypothesis space\"\n",
    "(you can think of it as a more general form of a hypothesis class).\n",
    "Letting $ \\theta $ be all possible real numbers, $ \\mathbb{R} $, we can create our hypothesis space $ \\mathcal{H} $:\n",
    "$$\n",
    "    \\mathcal{H} = \\Big\\{h(\\cdot, \\theta) ~\\colon~ \\theta \\in \\mathbb{R} \\Big\\}\n",
    "$$\n",
    "Where the $ \\cdot $ (dot) represents any input value.\n",
    "\n",
    "Because each such threshold classifier is uniquely determined by its threshold value $\\theta$, this hypothesis space is *parameterized* by $\\theta$.\n",
    "This means that the original optimization problem may be written as an optimization over $ \\theta $,\n",
    "where we slightly abuse notation to rewrite $ L $ as a function of $ \\theta $:\n",
    "$$\n",
    "\\min_{h\\in\\mathcal{H}} \\mathbb{E}_Z \\Big[ L(Z, h) \\Big] =  \\min_{\\theta} \\mathbb{E}_Z \\Big[ L(Z, \\theta) \\Big]\n",
    "$$\n",
    "\n",
    "It is very common in machine learning to choose hypothesis classes that are parameterized by numerical variables,\n",
    "this makes it easier to search over with a computer algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9853a4-9ed8-4e73-acaa-178236df0ff0",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange\";>★ Task 1.A</h3>\n",
    "\n",
    "Complete the function below that implements the threshold hypothesis function $ h(x, \\theta) $ described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0928c628-4212-447f-9c92-8b29479472d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_hypothesis(feature, theta):\n",
    "    \"\"\"\n",
    "    Our thresholding hypothesis function.\n",
    "    Predict True if x > theta, and False otherwise.\n",
    "\n",
    "    Args:\n",
    "      feature: A scalar \"titer\" value.\n",
    "\n",
    "    Returns:\n",
    "      ŷ: A boolean.\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883144d4-f003-40a5-9fd6-b7f6ed671725",
   "metadata": {},
   "source": [
    "### Selecting a Loss Function to Minimize\n",
    "\n",
    "In general, it is not possible to learn the true mapping of data to labels, $ f $, exactly.\n",
    "In fact, there may be no $ \\theta $, or no $ h \\in \\mathcal{H} $, such that $ h = f $.\n",
    "It could even be possible that \n",
    "$ f $ is not even a true *function*!\n",
    "There could be two patients with the same features but different infection labels,\n",
    "making it impossible for $ f $ to actually exist.\n",
    "\n",
    "Instead, we want to choose an $ h \\in \\mathcal{H} $ that closely approximates the true mapping $ f $.\n",
    "Mathematically, we introduce a [\"loss\" function](https://en.wikipedia.org//wiki/Loss_function) that imposes some\n",
    "[divergence](https://en.wikipedia.org/wiki/Divergence_(statistics)) between $ h $ and $ f $ and seek to minimize this loss.\n",
    "Essentially, we want a function (a loss function) that can tell us how well a hypothesis performs\n",
    "(higher loss values are typically bad and a zero loss means our hypothesis matches the data exactly).\n",
    "Minimizing a loss function is the central task in [mathematical optimization](https://en.wikipedia.org/wiki/Mathematical_optimization),\n",
    "and is thus central to machine learning.\n",
    "\n",
    "Though the world of loss functions is vast and theoretically rich,\n",
    "one simple loss function for binary classifiers is \"Zero-One\" loss.\n",
    "Zero-One loss outputs a zero loss (score) when our hypothesis, $ h $, and the true label mapping, $ f $, agree on a given example $ (x_i, y_i) $,\n",
    "and a one loss (score) otherwise.\n",
    "$$\n",
    "    L(Z, \\theta) = \\begin{cases}\n",
    "    0 & h(X, \\theta) = Y \\\\\n",
    "    1 & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "Minimizing Zero-One loss corresponds to maximizing the accuracy of a binary predictor, i.e.,\n",
    "minimizing the number of times our hypothesis disagrees with the true labels makes our predictor better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052f5b77-6cb2-4ca4-bd9c-eae584f9c52c",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange\";>★ Task 1.B</h3>\n",
    "\n",
    "Complete the function below which computes the Zero-One loss for the given hypothesis and theta on the given example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da6dc0-2e54-44a8-a055-47439274df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_one_loss(feature, label, hypothesis, theta):\n",
    "    \"\"\"\n",
    "    Zero-One Loss on a single example (feature, label), as a function of hypothesis and theta.\n",
    "\n",
    "    Args:\n",
    "      feature: A scalar \"titer\" value.\n",
    "      label: A boolean value corresponding to actual Covid-19 infection.\n",
    "      hypothesis: A function of (x, theta) that maps to predicted boolean label ŷ.\n",
    "      theta: A scalar titer threshold.\n",
    "\n",
    "    Returns:\n",
    "      0 or 1\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c04522-4e1d-4e97-8cc3-d893911403bb",
   "metadata": {},
   "source": [
    "## Part 2: Solving the Problem\n",
    "\n",
    "Now that we have formalisms for hypotheses and loss functions,\n",
    "we will work on finding the best hypothesis/parameters to solve our problem.\n",
    "The first step will be to evaluate how well a hypothesis and parameter are performing according to our loss function on our data.\n",
    "To do that, we can compute an expected loss that averages the loss over all data points:\n",
    "$$\n",
    "\\mathbb{E}_{Z} \\Big[ L(Z, h, \\theta) \\Big] = \\frac{1}{N} \\sum_{i = 1}^N L(z_i, h, \\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a3b677-4a7b-41b7-84ae-e7e3f8948293",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange\";>★ Task 2.A</h3>\n",
    "\n",
    "Complete the function below which calculates the average loss on the given examples (`features` and `labels`) as a function of the hypothesis and $ \\theta $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef9fbee-999a-47db-b4d9-6b909e2a83d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_loss(features, labels, loss_function, hypothesis, theta):\n",
    "    \"\"\"\n",
    "    Evaluates the average loss of the given hypothesis/theta over all examples.\n",
    "\n",
    "    Args:\n",
    "      features: the column of X feature (titer) values from empirical data.\n",
    "      labels: the column of Y label (infection) values from empirical data.\n",
    "      loss_function: A loss function.\n",
    "      hypothesis: A function of (x, theta) that maps to the predicted label ŷ.\n",
    "      theta: A scalar titer threshold.\n",
    "\n",
    "    Returns:\n",
    "      A scalar.\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2be223-c4ca-4134-b56f-94ad1ec85277",
   "metadata": {},
   "source": [
    "Since our example is simple, we can visualize the \"loss landscape\" (empirical loss as a function of $ \\theta $) directly.\n",
    "\n",
    "**The following step depends on Tasks 1.A, 1.B, and 2.A.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f31be1-a275-4fc2-afe1-ce9d87b5219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible threshold values (e.g. possible titer values).\n",
    "possible_thetas = list(range(X_values.min() - 1, X_values.max()))\n",
    "\n",
    "def evaluate_losses(features, labels, loss_function, expected_loss, hypothesis):\n",
    "    \"\"\"\n",
    "    Return a list of expected losses mapped from a list of possible theta values.\n",
    "    \"\"\"\n",
    "\n",
    "    # empirical loss for each threshold value\n",
    "    losses = []\n",
    "    for theta in possible_thetas:\n",
    "        losses.append(expected_loss(features, labels, loss_function, hypothesis, theta))\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be19a9-316f-48fc-a3c5-90bee69e22cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_landscape():\n",
    "    \"\"\"\n",
    "    Plot expected loss vs threshold value.\n",
    "    \"\"\"\n",
    "\n",
    "    pyplot.plot(possible_thetas, evaluate_losses(X_values, Y_values,\n",
    "                                                 zero_one_loss, expected_loss,\n",
    "                                                 threshold_hypothesis))\n",
    "    pyplot.title('Loss vs Threshold Value')\n",
    "    pyplot.xlabel('Threshold')\n",
    "    pyplot.ylabel('Average 0-1 Loss')\n",
    "\n",
    "plot_loss_landscape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd650311-6d76-4a5c-8cd4-1ea53221491e",
   "metadata": {},
   "source": [
    "Again, since our example is simple, we may find the loss-minimizing value of $\\theta$ by performing a direct search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff0bcad-8022-4f34-86dd-11cc374db492",
   "metadata": {},
   "source": [
    "#### Brute Force Search\n",
    "\n",
    "There are many optimization algorithms used in machine learning, each with countless tweaks and variations.\n",
    "One of the more famous methods, gradient descent, we will learn about later in this course.\n",
    "Nonetheless, **many** optimization algorithms are applicable to our current problem of empirical risk minimization;\n",
    "in some cases, more principled algorithms (such as convex optimization methods) will yield superior results, depending on the structure of the problem.\n",
    "To focus on the conceptual underpinnings of empirical risk minimization, here we will start with the simplest of algorithms: brute-force search.\n",
    "That is, we will compare all possible hypotheses (values of theta) and select the one that minimizes empirical loss.\n",
    "A brute force search is not always possible (like when there are infinite thetas), but in our specific case there are only so many possible titer values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ab0c2-9bee-4e89-b814-37b3ee740e4e",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange\";>★ Task 2.B</h3>\n",
    "\n",
    "Complete the function below which calculates the index of the minimum of a given loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb2413-d230-4e38-8d08-a8b6701b6443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_of_minimum(list_of_values):\n",
    "    \"\"\"\n",
    "    Return the index of minimum value from a list of values.\n",
    "    If there are multiple items that share the same minimum value,\n",
    "    then return the lowest index.\n",
    "\n",
    "    Args:\n",
    "      list_of_values: A list or array.\n",
    "\n",
    "    Return:\n",
    "      An integer index or None if the list is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac57df22-d5e0-4a72-8e23-671e19975a13",
   "metadata": {},
   "source": [
    "### Result: Learned Threshold Value\n",
    "\n",
    "According to the average Zero-One loss, what is the optimal threshold titer above which to predict an individual has Covid-19?\n",
    "The function bellow will finally answer this question.\n",
    "\n",
    "**This step depends on the previous tasks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b7df30-5aea-4585-a699-6ccfca288286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_force_minimize(possible_thetas, index_of_minimum, features, labels,\n",
    "                         loss_function, expected_loss, hypothesis):\n",
    "    best_index = index_of_minimum(evaluate_losses(features, labels, loss_function,\n",
    "                                                  expected_loss, hypothesis))\n",
    "    return possible_thetas[best_index]\n",
    "\n",
    "print(\n",
    "    \"Optimal threshold theta for raw accuracy: \",\n",
    "    brute_force_minimize(\n",
    "        possible_thetas, index_of_minimum,\n",
    "        X_values, Y_values, zero_one_loss, expected_loss, threshold_hypothesis\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b803212-e429-4c90-b5ec-badad45490d6",
   "metadata": {},
   "source": [
    "## Part 3: Assessing Risk\n",
    "\n",
    "In this part, we will learn how to evaluate our solution and consider the associated risks of deployment.\n",
    "In general, each of the steps we went through in previous parts are non-trivial and raises questions that are the subject of active research.\n",
    "For example:\n",
    " - Is our selection of variables appropriate, or do they induce bias in our predictor?\n",
    " - What loss functions naturally encode our objectives? Which have mathematical advantages? Which introduce systematic risks?\n",
    " - What algorithms are effective in which settings, and what theoretical results can we prove regarding speed, efficiency, or safety?\n",
    " - How do we use existing data effectively, again without introducing bias or systemic errors in our solutions?\n",
    " - Can our algorithms scale to larger datasets?\n",
    " - Can we choose algorithms that can guarantee our results are good enough?\n",
    "\n",
    "While we have found the threshold titer value that minimizes Zero-One loss and therefore maximizes accuracy,\n",
    "accuracy (especially evaluated only on the data used for training) is not necessarily the best quantity to optimize.\n",
    "For example, our Covid-19 data only has about 5% of patients that are infected.\n",
    "Predicting False for all data points would give an accuracy of 95%.\n",
    "The accuracy may be high, but the predictor is useless.\n",
    "\n",
    "Additionally, sometimes we care about certain types of errors more than others.\n",
    "Consider the following use for our titer-threshold classifier: we wish to screen visitors for entry to a ward of immunocompromised patients.\n",
    "If our classifier makes a mistake, we would rather it error on the side of caution and predict that someone has Covid-19 when they actually do not.\n",
    "This way even if we made an error, we protected the immunocompromised patients.\n",
    "In this example, optimizing for accuracy alone is not the best measure of utility.\n",
    "\n",
    "### Binary Classification Errors\n",
    "\n",
    "For binary classifiers, there are several classes of prediction outcomes that comprise a \"contingency table\" or [Confusion Matrix](https://en.wikipedia.org/wiki/Confusion_matrix) and which are worthy of dedicated names:\n",
    "\n",
    "<center><img src=\"confusion-matrix.png\"/></center>\n",
    "<center style='font-size: small'>Image courtesy of <a href='https://en.wikipedia.org/wiki/Confusion_matrix'>Wikipedia</a></center>\n",
    "\n",
    " - True Positives (TP) -- Also called a \"hit\". Represent instances that were correctly classified as positive/true.\n",
    " - True Negatives (TN) -- Represent instances that were correctly classified as negative/false.\n",
    " - False Positives (FP) -- Also called a \"Type I Error\". Represent instances that were incorrectly classified as positive/true.\n",
    " - False Negatives (FN) -- Also called a \"Type II Error\". Represent instances that were incorrectly classified as negative/false.\n",
    "\n",
    "From a confusion matrix, there are many different metrics you can compute\n",
    "(all telling you different things about your classifier and the dataset):\n",
    "\n",
    "| Metric                     | Definition                   |\n",
    "| -------------------------- | ---------------------------- |\n",
    "| True Positive Fraction     | $$ \\Pr(\\hat{Y}=1, Y=1)   $$  |\n",
    "| False Positive Fraction    | $$ \\Pr(\\hat{Y}=1, Y=0)   $$  |\n",
    "| True Negative Fraction     | $$ \\Pr(\\hat{Y}=0, Y=0)   $$  |\n",
    "| False Negative Fraction    | $$ \\Pr(\\hat{Y}=0, Y=1)   $$  |\n",
    "| True Positive Rate         | $$ \\Pr(\\hat{Y}=1 | Y=1) $$   |\n",
    "| False Positive Rate        | $$ \\Pr(\\hat{Y}=1 | Y=0) $$   |\n",
    "| True Negative Rate         | $$ \\Pr(\\hat{Y}=0 | Y=0) $$   |\n",
    "| False Negative Rate        | $$ \\Pr(\\hat{Y}=0 | Y=1) $$   |\n",
    "\n",
    "Let's walk through some of these metrics.\n",
    "\n",
    "\"True Positive Fraction\" ($ \\Pr(\\hat{Y}=1, Y=1) $) is the probability that both our prediction, $ \\hat{Y} $, and true label, $ Y $, are positive/true/1.\n",
    "Therefore, it would be the number of true positives over the total number of samples:\n",
    "$$\n",
    "\\mathrm{True Positive Fraction} = TP / N\n",
    "$$\n",
    "\n",
    "\"True Positive Rate\" ($ \\Pr(\\hat{Y}=1 | Y=1) $) is the probability that the predicted label, $ \\hat{Y} $, is positive *given* (conditioned on) the true label being positive.\n",
    "Therefore, it would be the number of true positives over the total number actual positives:\n",
    "$$\n",
    "\\mathrm{True Positive Rate} = TP / (TP + FN)\n",
    "$$\n",
    "\n",
    "Be aware that most of these metrics have different names in different fields.\n",
    "For example, \"True Positive Rate\" is also called \"recall\", \"sensitivity\", and \"probability of detection\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe1f4fa-4745-4287-b146-80fbac17bc93",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange\";>★ Task 3.A</h3>\n",
    "\n",
    "Complete the following functions, which calculate the frequencies of certain outcomes for a titer-threshold classifier on our empirical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a553dc7b-d45a-4a37-98ce-f68ef248477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positive_fraction(features, labels, hypothesis, theta):\n",
    "    \"\"\"\n",
    "    Returns Pr(Ŷ = 1, Y = 1) for the given hypothesis and theta.\n",
    "\n",
    "    Args:\n",
    "      features: the column of X feature (titer) values from empirical data.\n",
    "      labels: the column of Y label (infection) values from empirical data.\n",
    "      hypothesis: A function of (x, theta) that maps to the predicted label ŷ.\n",
    "      theta: A scalar titer threshold.\n",
    "\n",
    "    Return:\n",
    "      A float.\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented\n",
    "\n",
    "def false_positive_fraction(features, labels, hypothesis, theta):\n",
    "    \"\"\"\n",
    "    Returns Pr(Ŷ = 1, Y = 0) for the given hypothesis and theta.\n",
    "\n",
    "    Args:\n",
    "      features: the column of X feature (titer) values from empirical data.\n",
    "      labels: the column of Y label (infection) values from empirical data.\n",
    "      hypothesis: A function of (x, theta) that maps to the predicted label ŷ.\n",
    "      theta: A scalar titer threshold.\n",
    "\n",
    "    Return:\n",
    "      A float.\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented\n",
    "\n",
    "def true_negative_fraction(features, labels, hypothesis, theta):\n",
    "    \"\"\"\n",
    "    Returns Pr(Ŷ = 0, Y = 0) for the given hypothesis and theta.\n",
    "\n",
    "    Args:\n",
    "      features: the column of X feature (titer) values from empirical data.\n",
    "      labels: the column of Y label (infection) values from empirical data.\n",
    "      hypothesis: A function of (x, theta) that maps to the predicted label ŷ.\n",
    "      theta: A scalar titer threshold.\n",
    "\n",
    "    Return:\n",
    "      A float.\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented\n",
    "\n",
    "def false_negative_fraction(features, labels, hypothesis, theta):\n",
    "    \"\"\"\n",
    "    Returns Pr(Ŷ = 0, Y = 1) for the given hypothesis and theta.\n",
    "\n",
    "    Args:\n",
    "      features: the column of X feature (titer) values from empirical data.\n",
    "      labels: the column of Y label (infection) values from empirical data.\n",
    "      hypothesis: A function of (x, theta) that maps to the predicted label ŷ.\n",
    "      theta: A scalar titer threshold.\n",
    "\n",
    "    Return:\n",
    "      A float.\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf094fe-7a19-4aea-b46b-f714fee018c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style=\"color: darkorange\";>★ Task 3.B</h3>\n",
    "\n",
    "Complete the following functions, which calculate the frequencies of certain outcome rates for a titer-threshold classifier on our empirical data.\n",
    "Return `numpy.nan` if the desired quantity is undefined.\n",
    "\n",
    "*Hint: Use the functions you made in Task 3.A.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204bd728-ca55-4063-8211-30e12172ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positive_rate(features, labels, hypothesis, theta):\n",
    "    \"\"\"\n",
    "    Returns Pr(Ŷ = 1 | Y = 1) or numpy.nan (if the result is undefined)\n",
    "    for the given hypothesis and theta.\n",
    "\n",
    "    Args:\n",
    "      features: the column of X feature (titer) values from empirical data.\n",
    "      labels: the column of Y label (infection) values from empirical data.\n",
    "      hypothesis: A function of (x, theta) that maps to the predicted label ŷ.\n",
    "      theta: A scalar titer threshold.\n",
    "\n",
    "    Return:\n",
    "      A float or numpy.nan.\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented\n",
    "\n",
    "def false_positive_rate(features, labels, hypothesis, theta):\n",
    "    \"\"\"\n",
    "        Returns Pr(Ŷ = 1 | Y = 0) or numpy.nan (if the result is undefined)\n",
    "        for the given hypothesis and theta.\n",
    "\n",
    "    Args:\n",
    "      features: the column of X feature (titer) values from empirical data.\n",
    "      labels: the column of Y label (infection) values from empirical data.\n",
    "      hypothesis: A function of (x, theta) that maps to the predicted label ŷ.\n",
    "      theta: A scalar titer threshold.\n",
    "\n",
    "    Return:\n",
    "      A float or numpy.nan.\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented\n",
    "\n",
    "def true_negative_rate(features, labels, hypothesis, theta):\n",
    "    \"\"\"\n",
    "    Returns Pr(Ŷ = 0 | Y = 0) or numpy.nan (if the result is undefined)\n",
    "    for the given hypothesis and theta.\n",
    "\n",
    "    Args:\n",
    "      features: the column of X feature (titer) values from empirical data.\n",
    "      labels: the column of Y label (infection) values from empirical data.\n",
    "      hypothesis: A function of (x, theta) that maps to the predicted label ŷ.\n",
    "      theta: A scalar titer threshold.\n",
    "\n",
    "    Return:\n",
    "      A float or numpy.nan.\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented\n",
    "\n",
    "def false_negative_rate(features, labels, hypothesis, theta):\n",
    "    \"\"\"\n",
    "    Returns Pr(Ŷ = 0 | Y = 1) or numpy.nan (if the result is undefined)\n",
    "    for the given hypothesis and theta.\n",
    "\n",
    "    Args:\n",
    "      features: the column of X feature (titer) values from empirical data.\n",
    "      labels: the column of Y label (infection) values from empirical data.\n",
    "      hypothesis: A function of (x, theta) that maps to the predicted label ŷ.\n",
    "      theta: A scalar titer threshold.\n",
    "\n",
    "    Return:\n",
    "      A float or numpy.nan.\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d5db8-33b2-4a34-9818-b0fff0209ddd",
   "metadata": {},
   "source": [
    "### The ROC Curve\n",
    "\n",
    "One way to visualize the trade-offs between different types of binary classification errors is to plot the \"Receiver Operating Characteristics\" (ROC) (the name comes from using radar to classify incoming planes) of the classifier.\n",
    "ROC curves have true positive rate on the y-axis and false positive rate on the x-axis.\n",
    "<center><img src=\"roc-curve.png\"/></center>\n",
    "<center style='font-size: small'>Image courtesy of <a href='https://en.wikipedia.org/wiki/File:Roc_curve.svg'>Wikimedia Commons</a></center>\n",
    "\n",
    "Intuitively, you can look at an ROC curve as how well your classifier performs as you move a threshold vale.\n",
    "Starting at the origin of the x-axis, we have a zero false positive rate.\n",
    "This means that our classifier is very strict about predicting positive labels.\n",
    "But as we move along the x-axis, the false positive rate increases.\n",
    "Therefore, we get to see how our classifier performs as we become less and less strict about predicting positive labels.\n",
    "\n",
    "In general, the more area under the ROC curve, the better.\n",
    "In fact, there is a metric that just calculates the area under an ROC curve: [Area Under the ROC Curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve) (AUC or AuROC for short).\n",
    "\n",
    "**This step depends on most the previous tasks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f4952-10c2-465b-8079-74889bf1acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC(true_positive_rate, false_positive_rate, features, labels, hypothesis):\n",
    "    \"\"\"\n",
    "    Plot the receiver operating characteristics (true positive rate vs false positive rate)\n",
    "    for a given parametric hypothesis class and dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    tpr = [\n",
    "        true_positive_rate(features, labels, hypothesis, theta)\n",
    "        for theta in possible_thetas\n",
    "    ]\n",
    "\n",
    "    fpr = [\n",
    "        false_positive_rate(features, labels, hypothesis, theta)\n",
    "        for theta in possible_thetas\n",
    "    ]\n",
    "\n",
    "    min_theta = numpy.min(possible_thetas)\n",
    "    max_theta = numpy.max(possible_thetas)\n",
    "\n",
    "    color = matplotlib.cm.gist_earth(\n",
    "        (possible_thetas - min_theta) / (max_theta - min_theta)\n",
    "    )\n",
    "\n",
    "    ax = pyplot.gca()\n",
    "    for i in numpy.arange(len(possible_thetas) - 1):\n",
    "        ax.plot([fpr[i], fpr[i + 1]], [tpr[i], tpr[i + 1]], c=color[i])\n",
    "\n",
    "    cbar = pyplot.colorbar(\n",
    "        matplotlib.cm.ScalarMappable(\n",
    "            norm=matplotlib.colors.Normalize(min_theta, max_theta), cmap=matplotlib.cm.gist_earth\n",
    "        ),\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    cbar.set_label(\"Threshold (theta)\")\n",
    "    pyplot.title(\"Receiver Operating Characteristics of Threshold Classifier\")\n",
    "    pyplot.xlabel(\"False Positive Rate\")\n",
    "    pyplot.ylabel(\"True Positive Rate\")\n",
    "\n",
    "plot_ROC(true_positive_rate, false_positive_rate, X_values, Y_values, threshold_hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c9e95c-e4c5-40e9-b6b6-2575de4a6c66",
   "metadata": {},
   "source": [
    "### Precision-Recall Curve\n",
    "\n",
    "Another useful way to visualize the trade-offs between different types of binary classification errors is to plot the \"Precision-Recall Curve\",\n",
    "where \"recall\" is another name for true positive rate and \"precision\" is\n",
    "$$\n",
    "\\Pr(Y{=}1 \\mid \\hat{Y}{=}1)\n",
    "$$\n",
    "Precision-recall curves have precision on the y-axis and recall on the x-axis.\n",
    "Like ROC curves, they give us a way to visualize the trade-off between two different metrics.\n",
    "\n",
    "Also like ROC, more area under the curve is better and there is a metric for how much area is under the curve: Area Under the Precision-Recall Curve (AuPRC).\n",
    "\n",
    "**This step depends on most the previous tasks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76810a1-f07e-47f2-bcd4-6f89f4a34ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(features, labels, hypothesis, theta):\n",
    "    \"\"\"\n",
    "    Returns Pr(Y = 1 | Ŷ = 1) or numpy.nan if undefined for given hypothesis and theta.\n",
    "    \"\"\"\n",
    "\n",
    "    tp = true_positive_fraction(features, labels, hypothesis, theta)\n",
    "    fp = false_positive_fraction(features, labels, hypothesis, theta)\n",
    "\n",
    "    pp = tp + fp\n",
    "\n",
    "    if (pp == 0):\n",
    "        return numpy.nan\n",
    "\n",
    "    return tp / pp\n",
    "\n",
    "def plot_precision_recall(true_positive_rate, precision, features, labels, hypothesis):\n",
    "    \"\"\"\n",
    "    Plot precision vs recall (positive predictive value vs true positive rate)\n",
    "    for a given parametric hypothesis class and dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    tpr = [\n",
    "        true_positive_rate(features, labels, hypothesis, theta)\n",
    "        for theta in possible_thetas\n",
    "    ]\n",
    "    pp = [precision(features, labels, hypothesis, theta) for theta in possible_thetas]\n",
    "\n",
    "    min_theta = numpy.min(possible_thetas)\n",
    "    max_theta = numpy.max(possible_thetas)\n",
    "\n",
    "    color = matplotlib.cm.gist_earth(\n",
    "        (possible_thetas - min_theta) / (max_theta - min_theta)\n",
    "    )\n",
    "\n",
    "    ax = pyplot.gca()\n",
    "    for i in numpy.arange(len(possible_thetas) - 1):\n",
    "        ax.plot([tpr[i], tpr[i + 1]], [pp[i], pp[i + 1]], c=color[i])\n",
    "\n",
    "    cbar = pyplot.colorbar(\n",
    "        matplotlib.cm.ScalarMappable(\n",
    "            norm=matplotlib.colors.Normalize(min_theta, max_theta), cmap=matplotlib.cm.gist_earth\n",
    "        ),\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    cbar.set_label(\"Threshold (theta)\")\n",
    "    pyplot.title(\"Precision Recall Curve for Threshold Classifier\")\n",
    "    pyplot.xlabel(\"True Positive Rate\")\n",
    "    pyplot.ylabel(\"Positive Predictive Value\")\n",
    "\n",
    "plot_precision_recall(true_positive_rate, precision, X_values, Y_values, threshold_hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef094df-5a62-4a85-8cfc-1162246c03bf",
   "metadata": {},
   "source": [
    "In general, the use of plots such as the ROC or Precision vs Recall curve is highly contextual.\n",
    "For our purposes, these curves provide a useful demonstration of a truism in machine learning: there are always consequences and trade-offs.\n",
    "In particular, if we think of a high true positive rate as a \"good thing\" while a high false positive rate is a \"bad thing\",\n",
    "the ROC demonstrates that perfect classifiers (which would reside in the upper left corner of the ROC diagram and upper right corner of the PRC diagram) seldom exist,\n",
    "and that the space is characterized by an explicit trade-off between desirable classifier behaviors.\n",
    "\n",
    "Note that the optimal threshold value we found for accuracy is not the optimal threshold value as represented on the ROC or Precision vs Recall Curve!\n",
    "Even this basic binary classification example reveals a plethora of non-trivial trade-offs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4c04db-2030-46b2-8c52-e9a41c077312",
   "metadata": {},
   "source": [
    "Welcome to machine learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
